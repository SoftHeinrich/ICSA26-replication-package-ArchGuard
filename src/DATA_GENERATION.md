# Classification Data Generation Guide

This explains how to generate `classification_data_clean.json` files for training smell classifiers.

## Overview

The classification data generation pipeline transforms preprocessed project data (issues, smell evolution, component mappings) into labeled datasets suitable for machine learning.

**Pipeline Flow:**
```
Raw Project Data → [Preprocessing] → Enriched Data → [Data Generation] → classification_data_clean.json
```

## What's Included in This Package

This replication package includes the **data generation** scripts that create classification datasets from preprocessed artifacts:

```
src-rep/
├── preprocessing/
│   ├── gen_classification_data.py      # Main: Generate classification datasets
│   └── constants.py                    # Configuration constants
│
├── mapper/
│   ├── component_mapper.py            # Map issues to components
│   └── smell_to_issue_mapper.py       # Map smells to issues
│
├── commit/
│   ├── batch_dependency_analyzer.py   # Analyze dependency changes
│   └── dependency_change_detector.py  # Detect dependency changes
│
├── utils/
│   ├── rsf_utils.py                   # Parse RSF architecture files
│   ├── release_utils.py               # Version/release utilities
│   └── system_paths.py                # Path configuration
│
├── version/
│   └── mr_version_merger.py           # Enrich issues with version info
│
└── smell/
    └── analyze_smell_evolution.py     # Analyze smell changes over time
```

## Prerequisites

### What You Need Before Running

The data generation scripts require **preprocessed artifacts** from earlier pipeline stages:

1. **Issue Data** (from GitHub/GitLab scraping):
   - `data/issues/{system}/issues_all_batch_*.json` - Issue metadata
   - `data/issues/{system}/issues_all_discussions_batch_*.json` - Issue discussions
   - `data/issues/{system}/issues_all_diffs_batch_*.json` - MR/PR diffs
   - 
2. **Architecture Data** (from Understand + ARCADE):
   - `data/facts/{system}/{version}_deps.rsf` - Dependency facts
   - `data/clusters/{system}/acdc/{version}/*_clusters.rsf` - Component clusters

3. **Smell Data** (from ARCADE smell detection):
   - `data/smells/{system}/acdc/{version}/*_smells.json` - Detected smells
   - `data/smells/{system}/evolution/*_evolution.json` - Smell evolution

4. **Mapping Data** (generated by mapper scripts):
   - `data/mapping/{system}/mapping_{system}_{algorithm}.json` - Issue-to-component mappings
   - `data/mapping/{system}/evolution_to_issue_{system}_{algorithm}.json` - Smell-to-issue mappings

### External Tools (Not Included)

The **full preprocessing pipeline** requires external tools (not included in this package):
- **SciTools Understand** - Source code analysis
- **ARCADE Core** (Java) - Clustering and smell detection
- **MALLET** - Topic modeling
- Git repository access

**Note:** This package assumes you already have preprocessed data or can obtain it from the research artifacts.

## Usage

### Option 1: Generate Classification Data (Requires Preprocessed Data)

If you have preprocessed artifacts, generate classification datasets:

```bash
python -m preprocessing.gen_classification_data \
  --s2i data/mapping/inkscape/evolution_to_issue_inkscape_acdc.json \
  --mapping data/mapping/inkscape/mapping_inkscape_acdc.json \
  --issues data/issues/inkscape \
  --output-clean data/classification/inkscape/classification_data_clean.json \
  --output-dirty data/classification/inkscape/classification_data_dirty.json
```

**With dependency filtering:**
```bash
python -m preprocessing.gen_classification_data \
  --s2i data/mapping/inkscape/evolution_to_issue_inkscape_acdc.json \
  --mapping data/mapping/inkscape/mapping_inkscape_acdc.json \
  --issues data/issues/inkscape \
  --dep-checklist data/issues/inkscape/inkscape_commit_dependency_checklist.json \
  --output-clean data/classification/inkscape/classification_data_clean.json \
  --output-dirty data/classification/inkscape/classification_data_dirty.json
```

### Option 2: Generate Component Mappings (Requires Enriched Issues + Clusters)

Map issues to architectural components:

```bash
python -m mapper.component_mapper \
  --system inkscape \
  --issue-dir data/issues/inkscape \
  --cluster-dir data/clusters/inkscape/acdc \
  --output data/mapping/inkscape/mapping_inkscape_acdc.json
```

### Option 3: Generate Smell-to-Issue Mappings (Requires Smell Evolution + Mappings)

Link smell changes to issues:

```bash
python -m mapper.smell_to_issue_mapper \
  --evolution data/smells/inkscape/evolution/inkscape_acdc_evolution.json \
  --mapping data/mapping/inkscape/mapping_inkscape_acdc.json \
  --output data/mapping/inkscape/evolution_to_issue_inkscape_acdc.json
```

### Option 4: Analyze Dependency Changes (Optional Filtering)

Generate checklist of which MRs have dependency changes:

```bash
python -m commit.batch_dependency_analyzer \
  --issue-dir data/issues/inkscape \
  --output data/issues/inkscape/inkscape_commit_dependency_checklist.json
```

### Option 5: Analyze Smell Evolution (Requires Smell Data)

Track how smells change across versions:

```bash
python -m smell.analyze_smell_evolution \
  --smell-dir data/smells/inkscape/acdc \
  --output data/smells/inkscape/evolution/inkscape_acdc_evolution.json
```

## Output Format

### classification_data_clean.json

Deduplicated dataset where each issue appears once:

```json
[
  {
    "id": 123,
    "title": "Component initialization bug",
    "description": "Detailed description of the issue...",
    "discussion": "Filtered discussion (before first MR)...",
    "discussion_unfiltered": "Full discussion including post-MR comments...",
    "label": "smell",
    "version": "1.0,1.1,1.2"
  },
  {
    "id": 456,
    "title": "Feature request",
    "description": "Request for new feature...",
    "discussion": "Discussion about feature...",
    "discussion_unfiltered": "Full discussion...",
    "label": "no_smell",
    "version": "1.2"
  }
]
```

**Labels:**
- `"smell"` - Issue is linked to architectural smell changes
- `"no_smell"` - Issue is not linked to smells

### classification_data_dirty.json

Version-specific dataset where issues can appear multiple times:

```json
[
  {
    "id": 123,
    "title": "Component initialization bug",
    "description": "...",
    "discussion": "...",
    "label": "smell",
    "version": "1.0"
  },
  {
    "id": 123,
    "title": "Component initialization bug",
    "description": "...",
    "discussion": "...",
    "label": "smell",
    "version": "1.1"
  }
]
```



## Example: Complete Workflow for New Project

Assuming you have preprocessed data:

```bash
# 1. Generate component mappings
python -m mapper.component_mapper \
  --system myproject \
  --issue-dir data/issues/myproject \
  --cluster-dir data/clusters/myproject/acdc \
  --output data/mapping/myproject/mapping_myproject_acdc.json

# 2. Analyze smell evolution
python -m smell.analyze_smell_evolution \
  --smell-dir data/smells/myproject/acdc \
  --output data/smells/myproject/evolution/myproject_acdc_evolution.json

# 3. Link smells to issues
python -m mapper.smell_to_issue_mapper \
  --evolution data/smells/myproject/evolution/myproject_acdc_evolution.json \
  --mapping data/mapping/myproject/mapping_myproject_acdc.json \
  --output data/mapping/myproject/evolution_to_issue_myproject_acdc.json

# 4. (Optional) Analyze dependency changes
python -m commit.batch_dependency_analyzer \
  --issue-dir data/issues/myproject \
  --output data/issues/myproject/myproject_commit_dependency_checklist.json

# 5. Generate classification dataset
python -m preprocessing.gen_classification_data \
  --s2i data/mapping/myproject/evolution_to_issue_myproject_acdc.json \
  --mapping data/mapping/myproject/mapping_myproject_acdc.json \
  --issues data/issues/myproject \
  --dep-checklist data/issues/myproject/myproject_commit_dependency_checklist.json \
  --output-clean data/classification/myproject/classification_data_clean.json \
  --output-dirty data/classification/myproject/classification_data_dirty.json

# 6. Update dataset_config.py to point to your new data
# Edit classification/dataset_config.py:
# DATASET_BASE_DIR = Path("data/classification/myproject")

# 7. Run classification experiments
python -m casestudy.finetune_all --projects myproject
```

## Configuration

### Update Paths in dataset_config.py

After generating classification data, update `classification/dataset_config.py`:

```python
from pathlib import Path

# Base directory for all datasets
DATASET_BASE_DIR = Path("/path/to/your/data/classification")

# Map (project, detector) to folder names
DATASET_FOLDERS = {
    ("myproject", "acdc"): "myproject_acdc",
    # ... add your projects
}

# Available detectors per project
PROJECT_DETECTORS = {
    "myproject": ["acdc"],
    # ... add your projects
}
```